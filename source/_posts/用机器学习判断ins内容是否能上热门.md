---
title: ç”¨æœºå™¨å­¦ä¹ åˆ¤æ–­inså†…å®¹æ˜¯å¦èƒ½ä¸Šçƒ­é—¨
date: 2020-05-21 23:21:46
tags: [ç®—æ³•]
---

## èƒŒæ™¯

å‡è®¾ç°åœ¨è¦ä½¿ç”¨çˆ¬è™«ä»insæŠ“å–å†…å®¹,åœ¨insçš„ç½‘é¡µç‰ˆä¸Šæ¯ä¸ª#tagæ ‡ç­¾ä¸‹éƒ½æœ‰'çƒ­é—¨'å’Œ'æœ€æ–°'ä¸¤éƒ¨åˆ†tabé¡µ,å› ä¸ºçƒ­é—¨å†…å®¹çš„è´¨é‡æ›´å¥½,æ‰€ä»¥å¸Œæœ›èƒ½æŠ“å–æ›´å¤šçƒ­é—¨å†…å®¹,ä½†æ˜¯ç½‘é¡µç‰ˆæ¯ä¸ª#tagåªæ˜¾ç¤ºæœ€è¿‘çš„9æ¡çƒ­é—¨å†…å®¹,ä¸è¿‡'æœ€æ–°'tabä¸‹å¯ä»¥ä¸€ç›´å‘å‰ç¿»é¡µ,æ‰€ä»¥å¦‚æœèƒ½ä»'æœ€æ–°'ä¸‹çš„å†…å®¹ä¸­è¿‡æ»¤å‡ºçƒ­é—¨å†…å®¹å°±å¯ä»¥æ»¡è¶³å†…å®¹æŠ“å–è´¨é‡çš„è¦æ±‚,éœ€è¦æ‰¾åˆ°ä¸€ä¸ªèƒ½å°†å†…å®¹åˆ†ç±»ä¸ºçƒ­é—¨å’Œéçƒ­é—¨çš„ç®—æ³•.

<!--more-->


<div align=center> {% asset_img ins.png image %} </div>



é‚£ä¹ˆç°åœ¨æˆ‘æ¥ä»‹ç»ä¸€ä¸‹å¦‚ä½•ä½¿ç”¨æœºå™¨å­¦ä¹ æ¥å®ç°è¿™ä¸ªç®—æ³•,æœ¬æ–‡ä¸»è¦ä»‹ç»ä»é›¶å¼€å§‹ä½¿ç”¨æœºå™¨å­¦ä¹ å¹¶è§£å†³é—®é¢˜çš„è¿‡ç¨‹.ä¸ä¼šä»‹ç»ç†è®ºçŸ¥è¯†(åˆšå¥½æˆ‘ä¹Ÿä¸æ‡‚),é€Ÿæˆ˜é€Ÿå†³å°±å®Œäº‹å„¿äº†.

{% asset_img gan.jpg image %}

### å¼€å§‹ä¹‹å‰è¦äº†è§£

- **python**:ä¸€ç§è›‡
- **instagram**: è‘—åè¢«å¢™ç½‘ç«™ä¹‹ä¸€
- **pandas**:æ•°æ®å¤„ç†ç±»åº“
- **matplotlib&seaborn**: ç”»å›¾ç±»åº“
- **æœºå™¨å­¦ä¹ **: ä¸€ç§å¯¹è®¡ç®—æœºç®—æ³•çš„ç ”ç©¶æ–¹å¼ï¼Œç®—æ³•ä¼šæ ¹æ®ç»éªŒè‡ªåŠ¨ä¼˜åŒ–æ•ˆæœ
- **åˆ†ç±»é—®é¢˜**: æŠŠä¸€ç»„æ•°æ®åˆ†æˆä¸¤ç±»æˆ–è€…å¤šç±»,è¦åˆ’åˆ†ç±»å‹å·²æå‰å®šä¹‰
- **sklearn**: å°è£…äº†å¤šç§æœºå™¨å­¦ä¹ ç®—æ³•çš„ç±»åº“,å¼€ç®±å³ç”¨

## æ•°æ®å¤„ç†

inså†…å®¹æœ‰å¾ˆå¤šå­—æ®µä¿¡æ¯,é¦–å…ˆé€‰æ‹©å‡ºå¯èƒ½å½±å“å†…å®¹ä¸Šçƒ­é—¨çš„å­—æ®µ,åŒ…å«ç‚¹èµ/æ›å…‰/è¯„è®º/å‘å¸ƒæ—¶é—´/æŠ“å–æ—¶é—´/æ ‡é¢˜åŒ…å«çš„tagæ•°å’Œå½“å‰é¡µé¢tagä¸‹çš„å†…å®¹æ€»æ•°ç­‰,è¿™äº›å†…å®¹ç”¨jsonæ ¼å¼ä¿å­˜,ç¤ºä¾‹å¦‚ä¸‹:

```python
{
    "id":"CAA-r0SjtF3",
    "sourceTag":"dharmaproductions",
    "publishTime":1589130910000,
    "addTime":1589134125000,
    "likes":4,
    "comments":1,
    "views":18,
    "tagNumber":15,
    "description":"",
    "totalMedia":57149,
    "hot":1
}
```

### æ•°æ®æ¢ç´¢

è¿™ä¸€æ­¥æ˜¯ä¸ºäº†è¿›ä¸€æ­¥äº†è§£åŸå§‹æ•°æ®,æ£€æŸ¥æ•°æ®çœŸå®æ€§å’Œå­—æ®µçš„åˆ†å¸ƒ

1. ç”¨seabornç”»ç›´æ–¹å›¾,æŸ¥çœ‹çƒ­é—¨/éçƒ­é—¨å†…å®¹çš„æ¯”ä¾‹:

```python
    self.df = pd.read_json('debug/train_video.jl', lines=True)
    sns.countplot(self.df['hot'], label="Count")
```

<div align=center> {% asset_img hot.png image %} </div>

å›¾ä¸­çƒ­é—¨å†…å®¹å æ¯”è¿˜æ˜¯æ¯”è¾ƒé«˜çš„,æœ‰ä¸€ç‚¹è„±ç¦»çœŸå®æƒ…å†µ,å®é™…å¯¹äºinsä¸Šè¢«æ´»è·ƒä½¿ç”¨çš„tag,æœ¬èº«å†…å®¹æ•°é‡å°±å¾ˆå¤šåˆæ›´æ–°é¢‘ç¹,æ‰€ä»¥åªæœ‰å¾ˆå°‘ä¸€éƒ¨åˆ†å†…å®¹èƒ½ä¸Šçƒ­é—¨.

2. ç”¨seabornç”»çƒ­åŠ›å›¾,è¿™ä¸€æ­¥æ˜¯ä¸ºäº†æŸ¥çœ‹å­—æ®µä¹‹é—´çš„å…³ç³»:
```
    self.df = pd.read_json('debug/train_video.jl', lines=True)
    corr = self.df.corr()
    plt.figure(figsize=(14, 14))
    sns.heatmap(corr, annot=True)
```
corr()å‡½æ•°ä¼šè®¡ç®—æ•°æ®é›†dfä¸­å„å­—æ®µçš„ç›¸å…³å…³ç³»,å›¾ä¸­çš„é¢œè‰²è¶Šæµ…ä»£è¡¨è¶Šç›¸å…³,å¯ä»¥çœ‹åˆ°like/viewä¹‹å‰ç›¸å…³æ€§æ¯”è¾ƒé«˜,å¦‚æœä¸¤ä¸ªå­—æ®µä¹‹é—´ç›¸å…³æ€§æ¥è¿‘1,å¯ä»¥è€ƒè™‘å»æ‰å…¶ä¸­ä¸€ä¸ªå­—æ®µ.

<div align=left> {% asset_img heatmap.png image %} </div>

3. ç”¨matplotlibç”»é¢‘ç‡åˆ†å¸ƒç›´æ–¹å›¾

```python
    def draw_histo(self):
        plt.figure(1, figsize=(20, 20))
        i = 810
        for field in self.df.keys():
            i += 1
            # å»æ‰åŒºé—´ä¸Šæ•°é‡å°äº10çš„è®°å½•
            items = self.df.groupby(field).filter(lambda x: len(x) > 10)[field]
            self.histogram(items=items, index=i, field=field)
        plt.savefig('histogram.png')
        
        def histogram(self, items=None, index=None, field=None, y_label='Probability'):
        """
        ç”»é¢‘ç‡ç›´æ–¹å›¾ï¼ˆå¸¦æ­£æ€åˆ†å¸ƒæ›²çº¿ï¼‰
        :param index: å›¾ç‰‡ä½ç½®
        :param field: å­—æ®µå
        :param y_label:
        :return:
        """
        title = field + ' distribution'
        if items is None:
            items = self.df[field]
        try:
            plt.subplot(index)
            mean = items.mean()
            std = items.std()
            x = np.arange(items.min(), items.max())
            y = self.normfun(x=x, mu=mean, sigma=std)
            plt.plot(x, y)
            plt.hist(items, bins='auto', density=True, rwidth=0.9, stacked=True)
            plt.title(title)
            plt.xlabel(field)
            plt.ylabel(y_label)
            plt.tight_layout()
        except Exception as e:
            print(field)
            print(e)

    @staticmethod
    def normfun(x, mu, sigma):
        """
        æ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚å¯ä»¥ç†è§£æˆ x æ˜¯ muï¼ˆå‡å€¼ï¼‰å’Œ sigmaï¼ˆæ ‡å‡†å·®ï¼‰çš„å‡½æ•°
        :param x:
        :param mu:
        :param sigma:
        :return:
        """
        pdf = np.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / (sigma * np.sqrt(2 * np.pi))
        return pdf    
```
<div align=center> {% asset_img histogram.png image %} </div>

ç”»ç›´æ–¹å›¾çš„ç›®çš„æ˜¯æŸ¥çœ‹å­—æ®µçš„åˆ†å¸ƒç±»å‹,å›¾ä¸­è“è‰²çš„çº¿æ˜¯æ­£æ€åˆ†å¸ƒå‡½æ•°æ›²çº¿,æ˜ç»†like/view/commentçš„åˆ†å¸ƒä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒ,æ›´åƒæ˜¯é•¿å°¾åˆ†å¸ƒ(å¤§å¤šæ•°å€¼åˆ†å¸ƒåœ¨å¤´éƒ¨)


### æ•°æ®æ¸…æ´—&ç‰¹å¾é€‰æ‹©
å› ä¸ºåŸå§‹æ•°æ®ä¸­å¹¶æ²¡æœ‰ç¼ºå¤±å€¼æˆ–å¼‚å¸¸å€¼å¾—æƒ…å†µ,æ‰€ä»¥å¿½ç•¥æ•°æ®æ¸…æ´—çš„æ­¥éª¤,ç›´æ¥è¿›è¡Œç‰¹å¾é€‰æ‹©.
é¦–å…ˆæˆ‘ä»¬ä¸éœ€è¦å…·ä½“çš„æ—¶é—´æˆ³,æŠŠå‘å¸ƒæ—¶é—´publistTimeå’ŒæŠ“å–æ—¶é—´addTimeçš„é—´éš”è®¡ç®—å‡ºæ¥,å•ä½æ˜¯å¤©å’Œå°æ—¶(insçƒ­é—¨tabä¸­é€šå¸¸æ˜¯æœ€è¿‘å‘å¸ƒçš„å†…å®¹)

```python
    df['days'] = (pd.to_datetime(df['addTime'], unit='ms') - pd.to_datetime(df['publishTime'], unit='ms')).dt.days
    # ä¸æ»¡ä¸€å¤©çš„ç”¨1å¤©æ›¿æ¢
    df['days'] = df['days'].replace(0, 1)
    df['hours'] = ((pd.to_datetime(df['addTime'], unit='ms') - pd.to_datetime(df['publishTime'], unit='ms'))
                   .dt.total_seconds() / 3600).astype(int)
    df['hours'] = df['hours'].replace(0, 1)
```

ç„¶åå› ä¸ºä¸€èˆ¬å†…å®¹å‘å¸ƒè¶Šæ—©æ›å…‰ä¹Ÿè¶Šé«˜,æ‰€ä»¥æ·»åŠ like_per_hour/view_per_hourä¸¤ä¸ªç‰¹å¾,å‡å¼±æ—¶é—´å½±å“

```python
    df['like_per_hour'] = (df['likes'] / df['hours']).astype(int)
    df['view_per_hour'] = (df['views'] / df['hours']).astype(int)
```

æœ€åé€‰æ‹©çš„ç‰¹å¾å¦‚ä¸‹:

```python
    features = ['views', 'likes', 'comments', 'tagNumber', 'totalMedia', 'days', 'like_per_hour', 'view_per_hour']
```

## è¯„åˆ†æ ‡å‡†

åœ¨é€‰æ‹©åˆ†ç±»ç®—æ³•å‰,å…ˆæ¥äº†è§£ä¸€ä¸‹è¯„ä¼°åˆ†ç±»ç®—æ³•çš„å¸¸ç”¨æ ‡å‡†

### å‡†ç¡®ç‡,ç²¾ç¡®ç‡,å¬å›ç‡

å‡è®¾ä½ å¼€å‘äº†ä¸€æ¬¾æ£€æµ‹æ–°å† ç—…æ¯’çš„è¯•å‰‚ç›’,é‚£ä¹ˆæ¯æ¬¡æ£€æµ‹ç»“æœæœ‰ä¸€ä¸‹å››ç§(é˜³æ€§è¡¨ç¤ºè¢«æ£€æµ‹äººæºå¸¦ç—…æ¯’):

TP(True Prosivite): çœŸé˜³æ€§,è¯´æ˜æ­£ç¡®æ£€æµ‹å‡ºç—…æ¯’

FP(False Prosivite): å‡é˜³æ€§

TN(True Negative): çœŸé˜´æ€§

FN(False Negative): å‡é˜´æ€§,æºå¸¦ç—…æ¯’å´æ²¡æœ‰æ£€æµ‹å‡ºæ¥

å¯¹äºç—…æ¯’æ£€æµ‹æ¥è¯´FNçš„å±å®³æ˜¾ç„¶è¦æ¯”FPæ›´å¤§,è€Œæ ¹æ®è¿™å‡ ç§æƒ…å†µçš„æ ·æœ¬æ•°é‡å°±å¯ä»¥è®¡ç®—å‡ºå‡†ç¡®ç‡,ç²¾ç¡®ç‡å’Œå¬å›ç‡:

å‡†ç¡®ç‡(accuracy): ${TP+TN}\over{TP+FP+TN+FN}$,ä»£è¡¨å…¨éƒ¨æ ·æœ¬çš„æ­£ç¡®ç‡

ç²¾ç¡®ç‡(precision): ${TP}\over{TP+FP}$,ä»£è¡¨æ£€æµ‹ä¸ºé˜³æ€§æ—¶çš„æ­£ç¡®ç‡

å¬å›ç‡(recall): ${TP}\over{TP+FN}$,ä»£è¡¨æ‰€æœ‰ç—…æ¯’æºå¸¦è€…è¢«æ£€æµ‹ä¸ºé˜³æ€§çš„è¦†ç›–ç‡,ä¹Ÿå«æŸ¥å…¨ç‡


![ä¸¾ä¸ªä¾‹å­:][1]

æœ‰ä¸‰ä¸ªæ ·æœ¬,æ£€æµ‹ç»“æœä¸ºy_predict,è€Œå®é™…å€¼ä¸ºy_true,1ä»£è¡¨é˜³æ€§,sklearnçš„scoreå‡½æ•°é»˜è®¤è¿”å›çš„æ˜¯é˜³æ€§åˆ†ç±»çš„åˆ†æ•°

```python
from sklearn.metrics import accuracy_score,precision_score,recall_score

if __name__ == '__main__':
    y_predict = [1,0,1]
    y_true = [0,0,1]
    print(f'accuracy:{accuracy_score(y_true,y_predict)}')
    print(f'precision:{precision_score(y_true,y_predict)}')
    print(f'recall:{recall_score(y_true,y_predict)}')
```

è¾“å‡ºç»“æœä¸º:
accuracy:0.6666666666666666
precision:0.5
recall:1.0

å¯¹äºåˆ¤æ–­insæ˜¯å¦å±äºçƒ­é—¨å†…å®¹çš„ç®—æ³•,å¯ä»¥å…è®¸taæŠŠéçƒ­é—¨å†…å®¹åˆ†åˆ°çƒ­é—¨ä½†æ˜¯è¦å°½é‡ä¸é—æ¼çƒ­é—¨å†…å®¹ï¼Œå³FNè¶Šå°è¶Šå¥½ï¼ŒFP å¯ä»¥å¤§ä¸€äº›ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æ±‚**å¬å›ç‡è¶Šé«˜è¶Šå¥½,ç²¾ç¡®ç‡æ¬¡ä¹‹**

### å®å¹³å‡å’Œå¾®å¹³å‡

å¯¹äºæ±‚å‡†ç¡®ç‡è¿˜æœ‰å®å¹³å‡å’Œå¾®å¹³å‡ä¸¤ç§æ–¹å¼,å®å¹³å‡æ˜¯å¯¹ç›´æ¥æ¯ä¸ªåˆ†ç±»çš„å‡†ç¡®ç‡æ±‚å¹³å‡å€¼,è€Œå¾®å¹³å‡è¦å…ˆå¯¹æ‰€æœ‰åˆ†ç±»çš„é¢„æµ‹ç»“æœæ±‚å’Œå†è®¡ç®—å¹³å‡å€¼,ä¸¾ä¸ªä¾‹å­:

```
    Class A: 1 TP and 1 FP
    Class B: 10 TP and 90 FP
    Class C: 1 TP and 1 FP
    Class D: 1 TP and 1 FP
```
å¯¹äºä¸Šé¢çš„åˆ†ç±»ç»“æœ:

å‡†ç¡®ç‡ $pA=pC=pD=0.5$, $pB=0.1$

$å®å¹³å‡å‡†ç¡®ç‡(macro-avg)=$${0.5+0.1+0.5+0.5}\over{4}$$=0.4$

$å¾®å¹³å‡å‡†ç¡®ç‡(micro-avg)=$${1+10+1+1}\over{2+100+2+2}$$=0.123$


è¿™ä¸ªä¾‹å­ä½“ç°äº†å®å¹³å‡æŠŠæ‰€æœ‰åˆ†ç±»çš„**æƒé‡éƒ½è§†ä¸º1**çš„é—®é¢˜ï¼Œåœ¨è¿›è¡ŒCåˆ†ç±»æ—¶åªæœ‰0.1çš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”åˆ†ç±»Cçš„æ ·æœ¬æ•°å æ•´ä½“çš„90%ä»¥ä¸Šï¼Œå´æ²¡æœ‰å½±å“å®å¹³å‡çš„ç»“æœï¼Œæ‰€ä»¥ä¸€èˆ¬æŠŠå®å¹³å‡æ”¹è¿›ä¸ºåŠ æƒçš„å®å¹³å‡(æƒé‡æ˜¯åˆ†ç±»æ ·æœ¬å æ€»æ•°çš„æ¯”ä¾‹):
$macro-weight-avg=$$0.0189\times0.5+0.943\times0.1+0.0189\times0.5+0.0189\times0.5=0.123$

sklearnä¸­æ±‚å®å¹³å‡/å¾®å¹³å‡çš„ç²¾ç¡®ç‡,çŒœä¸‹ç»“æœæ˜¯å¤šå°‘?
```python
y_predict = [1,0,1]
y_true = [0,0,1]
macro=precision_score(y_true, y_predict,average="macro")
micro=precision_score(y_true, y_predict,average="micro")
```

## ç®—æ³•é€‰æ‹©
### sklearnå¸¸ç”¨åˆ†ç±»ç®—æ³•

**å†³ç­–æ ‘**: ä½¿ç”¨æ ‘å½¢ç»“æ„,æŠŠç‰¹å¾ä½œä¸ºå†³ç­–æ ‘ä¸Šçš„èŠ‚ç‚¹,å¶èŠ‚ç‚¹å°±æ˜¯åˆ†ç±»ç»“æœ,æ„é€ å†³ç­–æ ‘æ—¶è¿½æ±‚æœ€çº¯å‡€çš„åˆ†ç±»ç»“æœ(è¶Šçº¯å‡€åˆ™åˆ†ç±»çš„ä¸ç¡®å®šæ€§è¶Šä½)

**æœ´ç´ è´å¶æ–¯**: åœ¨ä½ ä¸çŸ¥é“äº‹ä»¶å…¨è²Œçš„æƒ…å†µä¸‹,å…ˆæ ¹æ®ä¸€ç‚¹äººç”Ÿç»éªŒå¾—åˆ°ä¸€ä¸ªä¸»è§‚åˆ¤æ–­,ç„¶åæ ¹æ®åç»­è§‚å¯Ÿç»“æœè¿›è¡Œä¿®æ­£.æ ¹æ®æ¦‚ç‡å¤§å°åˆ¤æ–­æœ€åçš„åˆ†ç±»,å¸¸ç”¨äºæ–‡æœ¬åˆ†ç±»

**SVM**: å‡ ä½•è§£æ³•,å…ˆæŠŠæ‰€æœ‰æ ·æœ¬ç”¨å¤šç»´ç©ºé—´çš„å‘é‡è¡¨ç¤º,ç„¶åæ±‚ä¸€ä¸ªå¹³é¢å°†ä¸åŒåˆ†ç±»çš„æ ·æœ¬åˆ†éš”å¼€

**KNN**: K-Nearest Neighbor,å‡ ä½•è§£æ³•,å› ä¸º"è¿‘æœ±è€…èµ¤,è¿‘å¢¨è€…é»‘",æ‰€ä»¥å¯¹äºèŠ‚ç‚¹A,ç›¸é‚»æœ€è¿‘çš„Kä¸ªèŠ‚ç‚¹æ˜¯ä»€ä¹ˆç±»å‹,Aå¤§æ¦‚å°±æ˜¯ä»€ä¹ˆç±»å‹

**é›†æˆç®—æ³•**: æœ¬ç€"äººå¤šåŠ›é‡å¤§"çš„åŸåˆ™,ä½¿ç”¨å¤šä¸ªåˆ†ç±»å™¨ä¸€èµ·å·¥ä½œ,æŒ‰åˆ†ç±»å™¨çš„åä½œæ–¹å¼åˆ†ä¸ºä¸¤ç§,bagging:åˆ†ç±»å™¨ä¸€èµ·æŠ•ç¥¨,çœ‹å“ªä¸ªåˆ†ç±»ç¥¨å¤š;boosting:å†å­¦ä¹ ,é€šè¿‡å¤šæ¬¡è¿­ä»£å¼ºåŒ–æ•´ä½“çš„åˆ†ç±»æ•ˆæœ

### æ•ˆæœå¯¹æ¯”
å‡†å¤‡äº†è®­ç»ƒæ•°æ®24wæ¡,æµ‹è¯•æ•°æ®2.7wæ¡,è®­ç»ƒæ•°æ®æ¥è‡ªä¸Šç™¾ä¸ªtag,éçƒ­é—¨å†…å®¹å æ¯”è¾ƒå°‘,æµ‹è¯•æ¥è‡ªä¸¤ä¸ªtag,éçƒ­é—¨æ•°æ®å æ¯”æ›´æ¥è¿‘æ•´ä½“æ¯”ä¾‹.
```python
import pandas as pd
from sklearn import naive_bayes
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.utils import shuffle

clf_list = {
    'cart': DecisionTreeClassifier(max_depth=5),
    # 'svm': svm.SVC(),  # å¤ªæ…¢äº†ï¼Œæ”¾å¼ƒ
    # 'nb_gauss': naive_bayes.GaussianNB(), # å¤ªå·®äº†ï¼Œæ”¾å¼ƒ
    'nb_multi': naive_bayes.MultinomialNB(),
    'k_neighbors': KNeighborsClassifier(),
    'adaptive_boost': AdaBoostClassifier(),
    'random_forest': RandomForestClassifier(max_depth=2)
}

def train():
    train_data = pd.read_json('debug/train_video.jl', lines=True)
    train_data = shuffle(train_data)

    # ç‰¹å¾é€‰æ‹©
    features = ['views', 'likes', 'comments', 'tagNumber', 'totalMedia', 'days', 'like_per_hour', 'view_per_hour']
    train_features = train_data[features]
    train_labels = train_data['hot']

    # æµ‹è¯•æ•°æ®
    test_data = pd.read_json('debug/test_video.jl', lines=True)
    test_data = shuffle(test_data)
    test_features = test_data[features]
    test_labels = test_data['hot']

    for k, clf in clf_list.items():
        print(f'-----{k} result-------')
        # å†³ç­–æ ‘è®­ç»ƒ
        clf.fit(train_features, train_labels)
        target_names = ['normal', 'hot']
        test_predict = clf.predict(test_features)
        sample_weight = test_labels.replace(1, 100).replace(0, 1)
        # æ‰“å°æµ‹è¯•æŠ¥å‘Š
        print(classification_report(test_labels, test_predict, target_names=target_names, sample_weight=sample_weight))
```
åœ¨æµ‹è¯•æŠ¥å‘Šä¸­,f1æ˜¯precision/recallçš„ç»¼åˆå¹³å‡åˆ†,supportæ˜¯åˆ†ç±»çš„æ ·æœ¬æƒé‡(é»˜è®¤æŒ‰æ ·æœ¬æ•°é‡è®¡ç®—æƒé‡).å› ä¸ºinså†…å®¹çƒ­é—¨æ•°é‡æ¯”è¾ƒå°‘,æ‰€ä»¥æˆ‘ç”¨sample_weightå‚æ•°æŠŠhotåˆ†ç±»çš„æƒé‡è°ƒæ•´ä¸ºnormalåˆ†ç±»çš„100å€,macro/weighted avgå°±æ˜¯ä¸Šé¢è¯´çš„å®å¹³å‡å’ŒåŠ æƒå®å¹³å‡.
è§‚å¯Ÿæµ‹è¯•æŠ¥å‘Šå¯ä»¥å‘ç°,CARTå†³ç­–æ ‘çš„å¯¹çƒ­é—¨å†…å®¹çš„å¬å›ç‡æœ€é«˜,è¾¾åˆ°92%,æœ´ç´ è´å¶æ–¯æ¬¡ä¹‹
```
-----cart result-------
              precision    recall  f1-score   support

      normal       0.44      0.90      0.59   24222.0
         hot       0.99      0.92      0.95  344800.0

    accuracy                           0.92  369022.0
   macro avg       0.72      0.91      0.77  369022.0
weighted avg       0.96      0.92      0.93  369022.0

-----nb_multi result-------
              precision    recall  f1-score   support

      normal       0.17      0.63      0.27   24222.0
         hot       0.97      0.79      0.87  344800.0

    accuracy                           0.78  369022.0
   macro avg       0.57      0.71      0.57  369022.0
weighted avg       0.92      0.78      0.83  369022.0

-----k_neighbors result-------
              precision    recall  f1-score   support

      normal       0.11      0.69      0.20   24222.0
         hot       0.97      0.63      0.76  344800.0

    accuracy                           0.63  369022.0
   macro avg       0.54      0.66      0.48  369022.0
weighted avg       0.91      0.63      0.72  369022.0

-----adaptive_boost result-------
              precision    recall  f1-score   support

      normal       0.08      0.99      0.15   24222.0
         hot       1.00      0.20      0.34  344800.0

    accuracy                           0.25  369022.0
   macro avg       0.54      0.60      0.24  369022.0
weighted avg       0.94      0.25      0.32  369022.0

-----random_forest result-------
              precision    recall  f1-score   support

      normal       0.10      0.96      0.18   24222.0
         hot       0.99      0.37      0.54  344800.0

    accuracy                           0.41  369022.0
   macro avg       0.54      0.67      0.36  369022.0
weighted avg       0.93      0.41      0.52  369022.0

```
ä¸ºäº†è¿›ä¸€æ­¥éªŒè¯ï¼Œå°†æµ‹è¯•é›†åˆ†ä¸º14ä¸ªå¤§å°2000çš„å­é›†ï¼Œç„¶ååˆ†åˆ«è®°å½•æ¯æ¬¡çš„æµ‹è¯•ç»“æœï¼Œç”»å‡ºæŠ˜çº¿å›¾ï¼Œé€‰æ‹©çš„æ ‡å‡†æ˜¯çƒ­é—¨å†…å®¹çš„å¬å›ç‡&ç²¾ç¡®ç‡å’Œæ•´ä½“çš„å‡†ç¡®ç‡ï¼Œåœ¨14æ¬¡æµ‹è¯•ä¸­CARTç®—æ³•éƒ½è¡¨ç°æœ€å¥½ã€‚
é‡å¤æµ‹è¯•çš„ä»£ç å¦‚ä¸‹ï¼š
```python
def train():
    train_data = pd.read_json('debug/train_video.jl', lines=True)
    train_data = shuffle(train_data)

    # ç‰¹å¾é€‰æ‹©
    features = ['views', 'likes', 'comments', 'tagNumber', 'totalMedia', 'days', 'like_per_hour', 'view_per_hour']
    train_features = train_data[features]
    train_labels = train_data['hot']

    # æµ‹è¯•æ•°æ®
    test_data = pd.read_json('debug/test_video.jl', lines=True)
    test_data = shuffle(test_data)

    # åˆ‡åˆ†ä¸ºæ¯ç»„å¤§å°ä¸º2000çš„é›†åˆ
    test_size = 2000
    test_list = [test_data[i:i + test_size] for i in range(0, test_data.shape[0], test_size)]
    reports = {}
    for k, clf in clf_list.items():
        print(f'-----{k} result-------')
        # å†³ç­–æ ‘è®­ç»ƒ
        clf.fit(train_features, train_labels)
        target_names = ['normal', 'hot']
        for test_set in test_list:
            test_features = test_set[features]
            test_labels = test_set['hot']
            test_predict = clf.predict(test_features)
            sample_weight = test_labels.replace(1, 100).replace(0, 1)
            report = classification_report(test_labels, test_predict, target_names=target_names,
                                           sample_weight=sample_weight, output_dict=True)
            reports.setdefault(f'{k}_hot_recall', []).append(report['hot']['recall'])
            reports.setdefault(f'{k}_hot_precision', []).append(report['hot']['precision'])
            reports.setdefault(f'{k}_accuracy', []).append(report['accuracy'])

    df = pd.DataFrame(reports)
    metrics = ['hot_recall', 'hot_precision', '_accuracy']
    fig, axes = plt.subplots(nrows=3, figsize=(16, 20))
    for i, m in enumerate(metrics):
        m_df = df.filter(regex=m)
        m_df.plot(ax=axes[i], title=m, xticks=range(1, len(test_list) + 1))
    fig.savefig(f"debug/report.png")
```
æµ‹è¯•ç»“æœ:
<div align=center> {% asset_img report.png image %} </div>

### æœªè§£å†³çš„é—®é¢˜

è¿™é‡Œæˆ‘ä»¬ç¼ºå¤±äº†æœºå™¨å­¦ä¹ æœ€å…³é”®çš„ä¸€æ­¥,é‚£å°±æ˜¯è°ƒå‚(æ‰‹åŠ¨ç‹—å¤´),æ€»æ„Ÿè§‰ä½¿ç”¨é»˜è®¤å‚æ•°çš„æ¨¡å‹æ²¡æœ‰çµé­‚.å› ä¸ºæŒ‰ç›´è§‰æ¥è¯´éšæœºæ£®æ—å’ŒAdaBooståº”è¯¥ä¼˜äºå†³ç­–æ ‘æ‰å¯¹,ç»“æœå‡†ç¡®ç‡å’Œå¬å›ç‡ç›¸å·®éƒ½å¾ˆå¤§
å¦å¤–æµ‹è¯•ç»“æœå®¹æ˜“å—æµ‹è¯•é›†å½±å“,å½“æˆ‘ä½¿ç”¨åªæœ‰39ä¸ªæ ·æœ¬ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªéçƒ­é—¨å†…å®¹çš„æµ‹è¯•é›†æ—¶ï¼Œå†³ç­–æ ‘çš„å¬å›ç‡åè€Œæœ€ä½ï¼Œæ‰€ä»¥é€‰æ‹©æµ‹è¯•é›†æ—¶è¦æ³¨æ„æ ·æœ¬æ•°é‡å’ŒçœŸå®æ€§.
```
-----cart result-------
              precision    recall  f1-score   support

      normal       0.00      1.00      0.00       1.0
         hot       1.00      0.79      0.88    3800.0

    accuracy                           0.79    3801.0
   macro avg       0.50      0.89      0.44    3801.0
weighted avg       1.00      0.79      0.88    3801.0

-----nb_multi result-------
              precision    recall  f1-score   support

      normal       0.01      1.00      0.02       1.0
         hot       1.00      0.97      0.99    3800.0

    accuracy                           0.97    3801.0
   macro avg       0.50      0.99      0.50    3801.0
weighted avg       1.00      0.97      0.99    3801.0

```


### ä¿å­˜åˆ†ç±»å™¨

æŠŠè¡¨ç°æœ€å¥½çš„CARTåˆ†ç±»å™¨æ¨¡å‹ä¿å­˜åˆ°ä»£ç æ–‡ä»¶ä¸­ï¼Œç„¶åå½“éœ€è¦å¯¹inså†…å®¹è¿›è¡Œåˆ†ç±»å°±å¯ä»¥ç›´æ¥ç”¨æ¨¡å‹è¿›è¡Œåˆ¤æ–­äº†.ä¿å­˜æ¨¡å‹æ—¶æˆ‘ä½¿ç”¨çš„æ˜¯cPickle(
é™¤äº†cPickleè¿˜å¯ä»¥ä½¿ç”¨joblib,python3.6ç›´æ¥import _pickleå³å¯ï¼Œè€Œjoblibè¿˜éœ€è¦å®‰è£…)
ä¿å­˜éå¸¸ç®€å•,è°ƒç”¨dump()å³å¯
```
import _pickle as cPickle
    # ä¿å­˜
    with open('ins_hot_model.clf','wb') as f:
        cPickle.dump(clf,f)
```
ä½¿ç”¨æ—¶éœ€è¦ä»æ–‡ä»¶ä¸­åŠ è½½åˆ†ç±»å™¨:
```
def use_model():
    # æœªåˆ†ç±»çš„insæ–‡æ¡£ä¿¡æ¯
    doc = {"likes": 107, "comments": 2, "views": 435.0, "tagNumber": 25, "totalMedia": 22000, "days": 1343,
           "like_per_hour": 0, "view_per_hour": 0}
    # è¯»å–åˆ†ç±»å™¨       
    clf = cPickle.load(open('ins_hot.clf', "rb"))
    # æŠŠæ–‡æ¡£è½¬æ¢ä¸ºDataFrame
    source = pd.DataFrame([doc], columns=list(doc.keys()))
    features = ['views', 'likes', 'comments', 'tagNumber', 'totalMedia', 'days', 'like_per_hour', 'view_per_hour']
    df = source[features]
    # ä¸ºæ–‡æ¡£åˆ†ç±»
    print(clf.predict(df))
```

## æ€»ç»“
ä½¿ç”¨æœºå™¨å­¦ä¹ è¿›è¡Œæ•°æ®åˆ†ææ—¶,éœ€è¦ç»è¿‡æ•°æ®é‡‡é›†,æ¸…æ´—,ç‰¹å¾é€‰æ‹©,æ¨¡å‹è®­ç»ƒå‡ ä¸ªè¿‡ç¨‹.å€ŸåŠ©sklearnåº“å¯ä»¥è®©æˆ‘ä»¬åœ¨ä¸äº†è§£ç®—æ³•åŸç†çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è½»æ¾åœ°ä½¿ç”¨æœºå™¨å­¦ä¹ è¿›è¡Œæ•°æ®åˆ†æ,è€Œå¯¹äºåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç”¨æœºå™¨å­¦ä¹ è§£å†³å®é™…é—®é¢˜,è¿˜æ˜¯éœ€è¦ä¸°å¯Œçš„ç»éªŒå’Œå¤§é‡çš„ä¼˜åŒ–éªŒè¯æ‰å¯ä»¥,çœ‹æ¥è¦æˆä¸ºé«˜è–ªçš„ç®—æ³•å·¥ç¨‹å¸ˆä¹Ÿä¸æ˜¯é‚£ä¹ˆå®¹æ˜“.
æ‰€ä»¥,äº²çˆ±çš„æœ‹å‹,ä½ æƒ³æˆä¸ºç®—æ³•å¤§ä½¬å—?ä½ æƒ³å­¦ä¹ æ•°æ®åˆ†æå—?ç°åœ¨æ‰«ç å³å¯8æŠ˜è´­ä¹°å‚åŠ æå®¢æ—¶é—´çš„æ•°æ®åˆ†æè¯¾ç¨‹å“¦ğŸ˜¯

<div align=center> {% asset_img jike_ad.jpeg image %} </div>




  [1]: https://throwsnew.com/images/example.jpg
  [2]: https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=2143959536,453965174&fm=26&gp=0.jpg